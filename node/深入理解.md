## 内存

### 内存限制
node基于v8进行构建, 所以其堆内存分配主要是由v8进行分配控制的, 在一般情况下, 64位系统和32位系统下分别只能使用约1.4GB和约0.7GB大小的堆内存。v8的堆内存空间由老生代内存空间和新生代内存空间组成,老生代内存空间限制是1400MB(64位)和700MB(32位), 新生代的内存空间限制是32MB(64位)和16MB(32位).

可以在node启动的时候出入以下参数修改node v8的堆内存限制
```bash
# 单位是MB
node --max-old-space-size=1700 test.js

# 单位是KB
node --max-new-space-size=1024 test.js
```

### 垃圾回收机制

v8的新生代中的对象主要通过Scavenge算法进项垃圾回收. 在Scanvenge的具体实现中, 主要是采用Cheney算法.新生代的内存更替是最快的, 所以Scavenge算法也是最快的一种垃圾回收算法.

v8的老生代的对象主要是通过Mark-Sweep(标记清除)和Mark-Compact算法相结合进行垃圾回收. 前者不进行内存整理, 速度更快, 但会产生很多内存碎片. 后者在前者的基础上演变而成, 速度更慢, 但会进行内存整理.

Scavenge算法只复制活着的对象(因为新生代中活着的对象更少), Mark-Sweep算法值清理死亡的对象(因为旧生代中死亡的对象更少), 这是这两种算法能高效运行的重要原因.

v8 通过增量标记、延迟清理、增量式整理等手段减少每次因为垃圾回收的js运行停顿时间.

```js
process.memoryUsage()

{
    rss: 22011904,
    heapTotal: 9682944,
    heapUsed: 5395328,
    external: 8718
}
```

rss 是resident set size 的缩写, 及进程的常驻内存部分. 进程的内存总共有几部分, 一部分是rss, 其余部分在交换区(swap)或者文件系统(filesystem)中. 除了rss为, headTotal 和 headUsed对应的是v8的堆内存信息. heapTotal是堆中总共申请的内存量, heapUsed表示目前堆中使用中的内存量. 这3个值得单位都是字节


Buffer 对象不同于其他对象, 它不经过v8的内存分配机制, 所以也不会有堆内存的大小限制(因为Buffer往往用于IO流, 数据量很大, 不应该作出限制). 所以对大文件操作, 不建议读进内存操作(例如fs.readFile或者fs.writeFile), 而应该使用流的方式(例如fs.createReadStream 或者fs.createWriteStream), 这样就不会受v8内存限制.

## Stream

node大文件复制(IO操作), 推荐使用Buffer和Stream, 因为这样不占用node的V8的堆内存, 提高性能。

由于在数据处理过程中会出现一个叫做[背压](https://en.wikipedia.org/wiki/Back_pressure#Backpressure_in_information_technology)的常见问题，它描述了数据传输过程中缓冲区后面数据的累积，当传输的接收端具有复杂的操作时，或者由于某种原因速度较慢时，来自传入源的数据就有累积的趋势，就像阻塞一样。

对于这种情况, 在使用Stream的过程中, 推荐使用pipe方法, 因为pipe方法内部对背压做了平衡优化.

以下是利用Stream实现的一个简单的复制文件的代码：

* (1) 监听来自可读流中的数据
* (2) 将数据写进可写流
* (3) 跟踪文件复制进度

```js
/*
    A file copy with streams and events - Author: Naren Arya
*/
const stream = require('stream');
const fs = require('fs');

let fileName = process.argv[2];
let destPath = process.argv[3];

const readabale = fs.createReadStream(fileName);
const writeable = fs.createWriteStream(destPath || "output");

fs.stat(fileName, (err, stats) => {
    this.fileSize = stats.size;
    this.counter = 1;
    this.fileArray = fileName.split('.');
    try {
        this.duplicate = destPath + "/" + this.fileArray[0] + '_Copy.' + this.fileArray[1];
    } catch(e) {
        console.exception('File name is invalid! please pass the proper one');
    }
    process.stdout.write(`File: ${this.duplicate} is being created:`);
    readabale.on('data', (chunk)=> {
        let percentageCopied = ((chunk.length * this.counter) / this.fileSize) * 100;
        process.stdout.clearLine();  // clear current text
        process.stdout.cursorTo(0);
        process.stdout.write(`${Math.round(percentageCopied)}%`);
        writeable.write(chunk);
        this.counter += 1;
    });
    readabale.on('end', (e) => {
        process.stdout.clearLine();  // clear current text
        process.stdout.cursorTo(0);
        process.stdout.write("Successfully finished the operation");
        return;
    });
    readabale.on('error', (e) => {
        console.log("Some error occured: ", e);
    });
    writeable.on('finish', () => {
        console.log("Successfully created the file copy!");
    });
});
```

用以上代码去复制一个7G大小的文件, 就会发现一个问题, 该node进程的内存占用达到了4.2G. 那是因为进程的读数据速度(约50MB/s)远快于数据的写数据速度(约15MB/s), 导致产生大量数据挤压在内存当中.

接下来, 我们优化一下以上代码:

```js
/*
    A file copy with streams and piping - Author: Naren Arya
*/
const stream = require('stream');
const fs = require('fs');

let fileName = process.argv[2];
let destPath = process.argv[3];

const readabale = fs.createReadStream(fileName);
const writeable = fs.createWriteStream(destPath || "output");

fs.stat(fileName, (err, stats) => {
    this.fileSize = stats.size;
    this.counter = 1;
    this.fileArray = fileName.split('.');
    try {
        this.duplicate = destPath + "/" + this.fileArray[0] + '_Copy.' + this.fileArray[1];
    } catch(e) {
        console.exception('File name is invalid! please pass the proper one');
    }
    process.stdout.write(`File: ${this.duplicate} is being created:`);
    readabale.on('data', (chunk) => {
        let percentageCopied = ((chunk.length * this.counter) / this.fileSize) * 100;
        process.stdout.clearLine();  // clear current text
        process.stdout.cursorTo(0);
        process.stdout.write(`${Math.round(percentageCopied)}%`);
        this.counter += 1;
    });
    readabale.pipe(writeable); // Auto pilot ON!
    // In case if we have an interruption while copying
    writeable.on('unpipe', (e) => {
        process.stdout.write("Copy has failed!");
    });
});;
```

优化的核心是将 writeable.write(chunk) 修改成 readabale.pipe(writeable), 此时node进程的内存占用情况为61.9MB. 而读数据速度 ≈ 写数据速度 ≈ 35MB, 达到了背压平衡的目的. 

## 多进程与多线程

- [深入理解Node.js 中的进程与线程](https://juejin.im/post/5d43017be51d4561f40adcf9)
- [真-Node多线程](https://juejin.im/post/5c63b5676fb9a049ac79a798)
- [https://blog.svend.cc/2019/05/26/node-child-process/](https://blog.svend.cc/2019/05/26/node-child-process/)


## 更多参考：

- [Writing memory efficient software applications in Node.js](https://medium.com/dev-bits/writing-memory-efficient-software-applications-in-node-js-5575f646b67f)
- [数据流中的积压问题](https://nodejs.org/zh-cn/docs/guides/backpressuring-in-streams/)
- [Backpressuring in Streams](https://nodejs.org/en/docs/guides/backpressuring-in-streams/)
- [nodejs 源码分析](https://github.com/fzxa/NodeJS-Nucleus-Plus-Internals)
- [nodejs是如何和libuv以及v8一起合作的？(文末有彩蛋哦)](https://blog.5udou.cn/#/blog/detail/nodejsShi-Ru-He-He-libuvYi-Ji-v8Yi-Qi-He-Zuo-De-Wen-Mo-You-Cai-Dan-Ou-84)
- [[译文]V8学习的高级进阶](https://blog.5udou.cn/#/blog/detail/Yi-Wen-V8Xue-Xi-De-Gao-Ji-Jin-Jie-92)